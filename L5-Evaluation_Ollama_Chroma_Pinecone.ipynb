{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# LangChain: Evaluation\n",
    "\n",
    "## Outline:\n",
    "\n",
    "* Example generation\n",
    "* Manual evaluation (and debugging)\n",
    "* LLM-assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28008949",
   "metadata": {},
   "source": [
    "## Create our QandA application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes.vectorstore import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f116b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "useLogging = True # set to True to get logging information (and hopefully track which LLM is called when)\n",
    "use_Ollama_For_Inference = True # set to True to use Ollama inference models (and pull at least the gemma:2b model)\n",
    "use_Ollama_For_Embedding = True # set to True to use Ollama embedddings models (and pull at least the nomic-embed-text:latest model)\n",
    "use_Pinecone = True #Turn on to use a Pinecone database. Sign up at www.pinecone.io for a free plan (including 5 indexes)\n",
    "use_Chroma = True #Turn on to use a local Chroma database. Supersedes the use_Pinecone flag above (and turns it off)\n",
    "use_Test_Data = False # set to True to use LimitedCSVLoader class below and only load the 577th item from the CSV file and test that querying with embeddings work well.\n",
    "\n",
    "import openai\n",
    "#Defaults to OpenAI if use_Ollama_For_Inference=False and use_Ollama_For_Inference=False\n",
    "openai.api_base = inferApiBase = embedApiBase =  \"https://api.openai.com/v1\"\n",
    "openai.base_url = inferBaseUrl = embedBaseUrl = \"https://api.openai.com\"\n",
    "openai.api_key = inferApiKey = embedApiKey = os.environ['OPENAI_API_KEY']\n",
    "embeddings_model_name = \"text-embedding-ada-002\"\n",
    "embeddings_model_name_short = \"ada\"\n",
    "embeddings_vector_size = 1536\n",
    "infer_model_name = \"gpt-3.5-turbo\"\n",
    "llm_platform = \"openai\"\n",
    "embed_chunk_size = 1000\n",
    "embed_overlap = 0\n",
    "\n",
    "\n",
    "if use_Ollama_For_Inference:\n",
    "    inferApiBase = \"http://localhost:11434/v1\"\n",
    "    inferBaseUrl = \"http://localhost:1143\"\n",
    "    inferApiKey = \"ollama\"\n",
    "    infer_model_name = \"gemma:2b\" #you can/should customize this to test different Ollama LLMs. Use the NAME field from `ollama list`\n",
    "\n",
    "\n",
    "if use_Ollama_For_Embedding:\n",
    "    llm_platform = \"ollama\"\n",
    "    embedApiBase = \"http://localhost:11434/v1\"\n",
    "    embedBaseUrl = \"http://localhost:1143\"\n",
    "    embedApiKey = \"ollama\"\n",
    "    #embeddings_model_name = \"mxbai-embed-large:latest\"\n",
    "    #embeddings_model_name_short = \"mxbai\"\n",
    "    #embeddings_vector_size = 1024\n",
    "    #embed_chunk_size = 512\n",
    "    #embed_overlap = 10\n",
    "    #\n",
    "    embeddings_model_name = \"nomic-embed-text:latest\" #you can/should customize this to test different Ollama LLMs. Use the NAME field from `ollama list`\n",
    "    embeddings_model_name_short = \"nomic\"\n",
    "    embeddings_vector_size = 768\n",
    "    embed_chunk_size = 8192\n",
    "    embed_overlap = 0\n",
    "\n",
    "print('Embed API Key:', embedApiKey)\n",
    "print('Infer API Key:', inferApiKey)\n",
    "print('Embed API Base:', embedApiBase)\n",
    "print('Infer API Base:', inferApiBase)\n",
    "print('Embeddings Model:', embeddings_model_name)\n",
    "print('Inference Model:', infer_model_name)\n",
    "\n",
    "index_prefix = \"langchain-deeplearningai-\" + embeddings_model_name_short + \"-\"\n",
    "if use_Test_Data:\n",
    "    index_prefix+='s-'\n",
    "rag_index_name = index_prefix + llm_platform\n",
    "print('RAG Index Name:', rag_index_name)\n",
    "\n",
    "if use_Chroma:\n",
    "    print('using Chroma Vector database')\n",
    "    \n",
    "    use_Pinecone = False\n",
    "    storage_path = os.environ.get('CHROMA_STORAGE_PATH')\n",
    "    if storage_path is None:\n",
    "        raise ValueError('CHROMA_STORAGE_PATH environment variable is not set')\n",
    "    \n",
    "\n",
    "elif use_Pinecone:\n",
    "\n",
    "    print('using Pinecone Vector database')\n",
    "    from pinecone import Pinecone\n",
    "    from langchain_pinecone import PineconeVectorStore\n",
    "    from tqdm.autonotebook import tqdm\n",
    "\n",
    "    PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "    PINECONE_ENV = os.environ.get(\"PINECONE_ENV\", \"PINECONE_ENV\")\n",
    "\n",
    "    if PINECONE_API_KEY is None:\n",
    "        raise ValueError(\"PINECONE_API_KEY environment variable not set.\")\n",
    "        # Name our index on Pineconeopenai.api_key\n",
    "\n",
    "    # Init pinecone\n",
    "    pc = Pinecone(\n",
    "        api_key=PINECONE_API_KEY,\n",
    "        source_tag=\"langchain-deeplearningai\"\n",
    "    )\n",
    "else:\n",
    "    print('using In Memory Vector database')\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "\n",
    "if use_Ollama_For_Embedding:\n",
    "    embeddings_model = OllamaEmbeddings(model=embeddings_model_name, embed_instruction='', query_instruction='')\n",
    "    #embeddings_model = OllamaEmbeddings(model=embeddings_model_name)\n",
    "else:\n",
    "    embeddings_model = OpenAIEmbeddings(model=embeddings_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec1106d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "file = 'OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=file, encoding='utf-8')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1393c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents.base import Document\n",
    "class LimitedCSVLoader(CSVLoader):\n",
    "    def load(self):\n",
    "        # Call the original load method to get all rows\n",
    "        all_rows = super().load()\n",
    "\n",
    "        # Restrict to the first 5 rows\n",
    "        #limited_rows = all_rows[:5]\n",
    "        # Restrict to line #577\n",
    "        limited_rows = all_rows[577]\n",
    "        if isinstance(limited_rows, Document):\n",
    "            limited_rows = [limited_rows]\n",
    "        return limited_rows\n",
    "    \n",
    "if use_Test_Data:\n",
    "    loader = LimitedCSVLoader(file_path=file, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f57fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=OllamaEmbeddings(model=embeddings_model_name, embed_instruction='', query_instruction='')\n",
    ").from_loaders([loader])\n",
    "\n",
    "db = index.vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "db = Chroma(collection_name=rag_index_name, embedding_function=embeddings_model, persist_directory=storage_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a2006054",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 16:07:31 - DEBUG - _config.py:load_ssl_context:80 - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-06-10 16:07:31 - DEBUG - _config.py:load_ssl_context_verify:146 - load_verify_locations cafile='h:\\\\Users\\\\Raphael\\\\OneDrive\\\\Perso\\\\Technical\\\\AI\\\\Training\\\\GenAI\\\\LangChain-for-LLM-Application-Development\\\\venv\\\\lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "2024-06-10 16:07:31 - DEBUG - _config.py:load_ssl_context:80 - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-06-10 16:07:31 - DEBUG - _config.py:load_ssl_context_verify:146 - load_verify_locations cafile='h:\\\\Users\\\\Raphael\\\\OneDrive\\\\Perso\\\\Technical\\\\AI\\\\Training\\\\GenAI\\\\LangChain-for-LLM-Application-Development\\\\venv\\\\lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "infer_model_name = 'llama3:8b'\n",
    "llm = ChatOpenAI(temperature = 0.0, base_url=inferApiBase, model=infer_model_name)\n",
    "#llm = ChatOpenAI(temperature = 0.0)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever= db.as_retriever(), \n",
    "    verbose=True,\n",
    "    chain_type_kwargs = {\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ebd73",
   "metadata": {},
   "source": [
    "### Coming up with test datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04a0f9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a88c2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "data[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d548aef",
   "metadata": {},
   "source": [
    "### Hard-coded examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c2d59bf2",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Do the Cozy Comfort Pullover Set have side pockets?\",\n",
    "        \"answer\": \"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What collection is the Ultra-Lofty 850 Stretch Down Hooded Jacket from?\",\n",
    "        \"answer\": \"The DownTek collection\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ce3e4f",
   "metadata": {},
   "source": [
    "### LLM-Generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f8376",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e87816",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a586c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "if useLogging:\n",
    "    import logging\n",
    "    import requests \n",
    "\n",
    "\n",
    "    logging.basicConfig(level=logging.DEBUG,\n",
    "                        format='%(asctime)s - %(levelname)s - %(filename)s:%(funcName)s:%(lineno)d - %(message)s',\n",
    "                        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "    requests.packages.urllib3.add_stderr_logger()\n",
    "    OLLAMA_DEBUG=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af659c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_model_name = \"gemma:2b\"\n",
    "llm = ChatOpenAI(temperature = 0.0, base_url=inferApiBase, model=infer_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62abae09",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "langchain.debug = False\n",
    "\n",
    "#llm = ChatOpenAI(temperature = 0.0) #use OpenAI\n",
    "\n",
    "example_gen_chain = QAGenerateChain.from_llm(llm)\n",
    "new_examples = example_gen_chain.apply(\n",
    "    ## t.page_content is required here for non-OpenAI LLMs. OpenAI is fine with both 't' and 't.page_content' but non-OpenAI LLMs generate a ValueError (see https://github.com/langchain-ai/langchain/issues/7559 for details)\n",
    "    [{\"doc\": t.page_content\n",
    "      .replace(\"'\", r\"\\'\")\n",
    "      .replace('\"',  '\\\"')\n",
    "      #.replace(\"®\", \"\")\n",
    "      #.replace('&', 'and')\n",
    "      #.replace('%', ' percent')\n",
    "      #.replace('–', '')\n",
    "      #.replace('!', '')\n",
    "      #.replace('+', 'plus')\n",
    "      #.replace(\" .\", \".\")\n",
    "      #.replace(\". \", \".\")\n",
    "      #.replace(\"°\", \" degrees\")\n",
    "      } \n",
    "      for t in data[:3]]\n",
    "    #[{\"doc\": re.sub('[^A-Za-z0-9 -]+', '', t.page_content)} for t in data[:4]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ab28b5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9417c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_examples = [item['qa_pairs'] for item in new_examples]\n",
    "transformed_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebe4228",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf25f2f",
   "metadata": {},
   "source": [
    "### Combine examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ada2a3fc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "examples += transformed_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "645e3937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Do the Cozy Comfort Pullover Set have side pockets?',\n",
       "  'answer': 'Yes'},\n",
       " {'query': 'What collection is the Ultra-Lofty 850 Stretch Down Hooded Jacket from?',\n",
       "  'answer': 'The DownTek collection'},\n",
       " {'query': \"What is the weight of a pair of Women's Campside Oxfords?\",\n",
       "  'answer': '1 lb.1 oz. per pair.'},\n",
       " {'query': 'What is the purpose of the recycled waterhog dog mat?',\n",
       "  'answer': 'The purpose of the recycled waterhog dog mat is to protect floors from spills and splashing with its ultradurable construction made from recycled plastic materials.'},\n",
       " {'query': \"What is the main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit?\",\n",
       "  'answer': \"The main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit is its bright colors, ruffles, and exclusive whimsical prints.\"}]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9cdf5cf5",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 16:13:09,257 DEBUG Starting new HTTP connection (1): localhost:11434\n",
      "2024-06-10 16:13:09 - DEBUG - connectionpool.py:_new_conn:244 - Starting new HTTP connection (1): localhost:11434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 16:13:13,558 DEBUG http://localhost:11434 \"POST /api/embeddings HTTP/1.1\" 200 None\n",
      "2024-06-10 16:13:13 - DEBUG - connectionpool.py:_make_request:549 - http://localhost:11434 \"POST /api/embeddings HTTP/1.1\" 200 None\n",
      "2024-06-10 16:13:13 - DEBUG - _base_client.py:_build_request:446 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': \"Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n: 2\\nname: Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece\\ndescription: She'll love the bright colors, ruffles and exclusive whimsical prints of this toddler's two-piece swimsuit! Our four-way-stretch and chlorine-resistant fabric keeps its shape and resists snags. The UPF 50+ rated fabric provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays. The crossover no-slip straps and fully lined bottom ensure a secure fit and maximum coverage. Machine wash and line dry for best results. Imported.<<<<>>>>>: 769\\nname: Girls' Aquatic Adventure Swimsuit, One-piece, Long Sleeve, Colorblock\\ndescription: Whether it's relaxing on the beach or paddling on the water, this long-sleeved, UPF 50+ rated girls' swimsuit makes it easy to focus on the fun. Fabric & Care: 78% recycled nylon, 22% Xtra Life Lycra. Machine wash, line dry. Additional Features: UPF 50+ rated, the highest rated sun protection possible. Made from recycled content from fishing nets to help minimize our environmental impact. Long sleeves offers great coverage; no need to layer on a rash guard. Breathable and quick drying, with comfortable stretch for great freedom of movement. Front zipper for easy on-off, even when wet. Imported.<<<<>>>>>: 285\\nname: Beach Babe Reversible Swimsuit\\ndescription: Designed to stay put, this sporty swimsuit is ideal for girls who love to play hard in and around the water. Plus, the reversible design gives her two options in one. Fabric & Care: 86% nylon, 14% Lycra. UPF 50+ rated – the highest rated sun protection possible. Solid on one side, colorblock on the other. Back tie lets her find the perfect fit. Machine wash, line dry. Imported. Additional Features: Our high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun's harmful rays. This fabric is recommended by The Skin Cancer Foundation as an effective UV protectant.<<<<>>>>>: 283\\nname: Curvy Control Swimsuit\\ndescription: Look and feel your best in this slimming high-waist bikini bottom featuring a vibrant geometric print. Pair it with one of our Slimming Swimwear tops for your most flattering suit ever.\\r\\n\\r\\nSize & Fit\\r\\nForm Fitting: Fits close to the body.\\r\\n\\r\\nWhy We Love It\\r\\nAt , we believe every body is a beach body. Our Slimming Swimwear is designed to help you feel great about your figure – with all the comfort and coverage you need, plus guaranteed-to-flatter details that will have you feeling more confident than ever before. As one customer raves, “I’ve been afraid to be seen in swimsuits forever, but not anymore!”\\r\\n\\r\\nFabric & Care\\r\\nPremium nylon/Lycra® Xtra Life Italian blend is breathable, quick drying and chlorine resistant. Lycra Xtra Life provides long-lasting fit. It resists degradation from sun, chlorine and heat up to 10 times longer than unprotected fabrics. 72% nylon, 28% Lycra Xtra Life. UPF 50+ rated – the highest rated sun protection possible. Handwash, line dry.\\r\\n\\r\\nAdditional Features\\r\\nInnovative fabrics for added\", 'role': 'system'}, {'content': \"What is the main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit?\", 'role': 'user'}], 'model': 'llama3:8b', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-10 16:13:13 - DEBUG - _base_client.py:_request:949 - Sending HTTP Request: POST http://localhost:11434/v1/chat/completions\n",
      "2024-06-10 16:13:13 - DEBUG - _trace.py:trace:45 - close.started\n",
      "2024-06-10 16:13:13 - DEBUG - _trace.py:trace:45 - close.complete\n",
      "2024-06-10 16:13:13 - DEBUG - _trace.py:trace:45 - connect_tcp.started host='localhost' port=11434 local_address=None timeout=None socket_options=None\n",
      "2024-06-10 16:13:15 - DEBUG - _trace.py:trace:45 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024C456DF730>\n",
      "2024-06-10 16:13:15 - DEBUG - _trace.py:trace:45 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-10 16:13:15 - DEBUG - _trace.py:trace:45 - send_request_headers.complete\n",
      "2024-06-10 16:13:15 - DEBUG - _trace.py:trace:45 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-10 16:13:15 - DEBUG - _trace.py:trace:45 - send_request_body.complete\n",
      "2024-06-10 16:13:15 - DEBUG - _trace.py:trace:45 - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-10 16:13:29 - DEBUG - _trace.py:trace:45 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Mon, 10 Jun 2024 14:13:29 GMT'), (b'Content-Length', b'523')])\n",
      "2024-06-10 16:13:29 - INFO - _client.py:_send_single_request:1026 - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-10 16:13:29 - DEBUG - _trace.py:trace:45 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-10 16:13:29 - DEBUG - _trace.py:trace:45 - receive_response_body.complete\n",
      "2024-06-10 16:13:29 - DEBUG - _trace.py:trace:45 - response_closed.started\n",
      "2024-06-10 16:13:29 - DEBUG - _trace.py:trace:45 - response_closed.complete\n",
      "2024-06-10 16:13:29 - DEBUG - _base_client.py:_request:988 - HTTP Response: POST http://localhost:11434/v1/chat/completions \"200 OK\" Headers({'content-type': 'application/json', 'date': 'Mon, 10 Jun 2024 14:13:29 GMT', 'content-length': '523'})\n",
      "2024-06-10 16:13:29 - DEBUG - _base_client.py:_request:996 - request_id: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"According to the description, one of the main features of the Infant and Toddler Girls' Coastal Chill Swimsuit is its UPF 50+ rated fabric, which provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays.\""
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke(examples[4][\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3cb08",
   "metadata": {},
   "source": [
    "## Manual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "fcaf622e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "8a142638",
   "metadata": {
    "height": 30,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 16:14:28,740 DEBUG Starting new HTTP connection (1): localhost:11434\n",
      "2024-06-10 16:14:28 - DEBUG - connectionpool.py:_new_conn:244 - Starting new HTTP connection (1): localhost:11434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 16:14:33,082 DEBUG http://localhost:11434 \"POST /api/embeddings HTTP/1.1\" 200 None\n",
      "2024-06-10 16:14:33 - DEBUG - connectionpool.py:_make_request:549 - http://localhost:11434 \"POST /api/embeddings HTTP/1.1\" 200 None\n",
      "2024-06-10 16:14:33 - DEBUG - _base_client.py:_build_request:446 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': \"Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n: 2\\nname: Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece\\ndescription: She'll love the bright colors, ruffles and exclusive whimsical prints of this toddler's two-piece swimsuit! Our four-way-stretch and chlorine-resistant fabric keeps its shape and resists snags. The UPF 50+ rated fabric provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays. The crossover no-slip straps and fully lined bottom ensure a secure fit and maximum coverage. Machine wash and line dry for best results. Imported.<<<<>>>>>: 769\\nname: Girls' Aquatic Adventure Swimsuit, One-piece, Long Sleeve, Colorblock\\ndescription: Whether it's relaxing on the beach or paddling on the water, this long-sleeved, UPF 50+ rated girls' swimsuit makes it easy to focus on the fun. Fabric & Care: 78% recycled nylon, 22% Xtra Life Lycra. Machine wash, line dry. Additional Features: UPF 50+ rated, the highest rated sun protection possible. Made from recycled content from fishing nets to help minimize our environmental impact. Long sleeves offers great coverage; no need to layer on a rash guard. Breathable and quick drying, with comfortable stretch for great freedom of movement. Front zipper for easy on-off, even when wet. Imported.<<<<>>>>>: 285\\nname: Beach Babe Reversible Swimsuit\\ndescription: Designed to stay put, this sporty swimsuit is ideal for girls who love to play hard in and around the water. Plus, the reversible design gives her two options in one. Fabric & Care: 86% nylon, 14% Lycra. UPF 50+ rated – the highest rated sun protection possible. Solid on one side, colorblock on the other. Back tie lets her find the perfect fit. Machine wash, line dry. Imported. Additional Features: Our high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun's harmful rays. This fabric is recommended by The Skin Cancer Foundation as an effective UV protectant.<<<<>>>>>: 283\\nname: Curvy Control Swimsuit\\ndescription: Look and feel your best in this slimming high-waist bikini bottom featuring a vibrant geometric print. Pair it with one of our Slimming Swimwear tops for your most flattering suit ever.\\r\\n\\r\\nSize & Fit\\r\\nForm Fitting: Fits close to the body.\\r\\n\\r\\nWhy We Love It\\r\\nAt , we believe every body is a beach body. Our Slimming Swimwear is designed to help you feel great about your figure – with all the comfort and coverage you need, plus guaranteed-to-flatter details that will have you feeling more confident than ever before. As one customer raves, “I’ve been afraid to be seen in swimsuits forever, but not anymore!”\\r\\n\\r\\nFabric & Care\\r\\nPremium nylon/Lycra® Xtra Life Italian blend is breathable, quick drying and chlorine resistant. Lycra Xtra Life provides long-lasting fit. It resists degradation from sun, chlorine and heat up to 10 times longer than unprotected fabrics. 72% nylon, 28% Lycra Xtra Life. UPF 50+ rated – the highest rated sun protection possible. Handwash, line dry.\\r\\n\\r\\nAdditional Features\\r\\nInnovative fabrics for added\", 'role': 'system'}, {'content': \"What is the main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit?\", 'role': 'user'}], 'model': 'llama3:8b', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-10 16:14:33 - DEBUG - _base_client.py:_request:949 - Sending HTTP Request: POST http://localhost:11434/v1/chat/completions\n",
      "2024-06-10 16:14:33 - DEBUG - _trace.py:trace:45 - close.started\n",
      "2024-06-10 16:14:33 - DEBUG - _trace.py:trace:45 - close.complete\n",
      "2024-06-10 16:14:33 - DEBUG - _trace.py:trace:45 - connect_tcp.started host='localhost' port=11434 local_address=None timeout=None socket_options=None\n",
      "2024-06-10 16:14:35 - DEBUG - _trace.py:trace:45 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024C456DF5B0>\n",
      "2024-06-10 16:14:35 - DEBUG - _trace.py:trace:45 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-10 16:14:35 - DEBUG - _trace.py:trace:45 - send_request_headers.complete\n",
      "2024-06-10 16:14:35 - DEBUG - _trace.py:trace:45 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-10 16:14:35 - DEBUG - _trace.py:trace:45 - send_request_body.complete\n",
      "2024-06-10 16:14:35 - DEBUG - _trace.py:trace:45 - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-10 16:14:49 - DEBUG - _trace.py:trace:45 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Mon, 10 Jun 2024 14:14:49 GMT'), (b'Content-Length', b'523')])\n",
      "2024-06-10 16:14:49 - INFO - _client.py:_send_single_request:1026 - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-10 16:14:49 - DEBUG - _trace.py:trace:45 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-10 16:14:49 - DEBUG - _trace.py:trace:45 - receive_response_body.complete\n",
      "2024-06-10 16:14:49 - DEBUG - _trace.py:trace:45 - response_closed.started\n",
      "2024-06-10 16:14:49 - DEBUG - _trace.py:trace:45 - response_closed.complete\n",
      "2024-06-10 16:14:49 - DEBUG - _base_client.py:_request:988 - HTTP Response: POST http://localhost:11434/v1/chat/completions \"200 OK\" Headers({'content-type': 'application/json', 'date': 'Mon, 10 Jun 2024 14:14:49 GMT', 'content-length': '523'})\n",
      "2024-06-10 16:14:49 - DEBUG - _base_client.py:_request:996 - request_id: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': \"What is the main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit?\",\n",
       " 'result': \"According to the description, one of the main features of the Infant and Toddler Girls' Coastal Chill Swimsuit is its UPF 50+ rated fabric, which provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays.\"}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke(examples[4][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b3d6bef0",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Turn off the debug mode\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bdbdce",
   "metadata": {},
   "source": [
    "## LLM assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dca05a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "predictions = qa.apply(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "6012a3e0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "724b1c0b",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "#llm = ChatOpenAI(temperature=0)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8b46ae55",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 16:08:10 - DEBUG - _base_client.py:_build_request:446 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': \"You are a teacher grading a quiz.\\nYou are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\\n\\nExample Format:\\nQUESTION: question here\\nSTUDENT ANSWER: student's answer here\\nTRUE ANSWER: true answer here\\nGRADE: CORRECT or INCORRECT here\\n\\nGrade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \\n\\nQUESTION: Do the Cozy Comfort Pullover Set have side pockets?\\nSTUDENT ANSWER: According to the product description, yes, the Cozy Comfort Pullover Set has side pockets in the pull-on pants.\\nTRUE ANSWER: Yes\\nGRADE:\", 'role': 'user'}], 'model': 'llama3:8b', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-10 16:08:10 - DEBUG - _base_client.py:_request:949 - Sending HTTP Request: POST http://localhost:11434/v1/chat/completions\n",
      "2024-06-10 16:08:10 - DEBUG - _trace.py:trace:45 - connect_tcp.started host='localhost' port=11434 local_address=None timeout=None socket_options=None\n",
      "2024-06-10 16:08:12 - DEBUG - _trace.py:trace:45 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024C455245E0>\n",
      "2024-06-10 16:08:12 - DEBUG - _trace.py:trace:45 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:12 - DEBUG - _trace.py:trace:45 - send_request_headers.complete\n",
      "2024-06-10 16:08:12 - DEBUG - _trace.py:trace:45 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:12 - DEBUG - _trace.py:trace:45 - send_request_body.complete\n",
      "2024-06-10 16:08:12 - DEBUG - _trace.py:trace:45 - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:18 - DEBUG - _trace.py:trace:45 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Mon, 10 Jun 2024 14:08:18 GMT'), (b'Content-Length', b'299')])\n",
      "2024-06-10 16:08:18 - INFO - _client.py:_send_single_request:1026 - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-10 16:08:18 - DEBUG - _trace.py:trace:45 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:18 - DEBUG - _trace.py:trace:45 - receive_response_body.complete\n",
      "2024-06-10 16:08:18 - DEBUG - _trace.py:trace:45 - response_closed.started\n",
      "2024-06-10 16:08:18 - DEBUG - _trace.py:trace:45 - response_closed.complete\n",
      "2024-06-10 16:08:18 - DEBUG - _base_client.py:_request:988 - HTTP Response: POST http://localhost:11434/v1/chat/completions \"200 OK\" Headers({'content-type': 'application/json', 'date': 'Mon, 10 Jun 2024 14:08:18 GMT', 'content-length': '299'})\n",
      "2024-06-10 16:08:18 - DEBUG - _base_client.py:_request:996 - request_id: None\n",
      "2024-06-10 16:08:18 - DEBUG - _base_client.py:_build_request:446 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': \"You are a teacher grading a quiz.\\nYou are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\\n\\nExample Format:\\nQUESTION: question here\\nSTUDENT ANSWER: student's answer here\\nTRUE ANSWER: true answer here\\nGRADE: CORRECT or INCORRECT here\\n\\nGrade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \\n\\nQUESTION: What collection is the Ultra-Lofty 850 Stretch Down Hooded Jacket from?\\nSTUDENT ANSWER: The Ultra-Lofty 850 Stretch Down Hooded Jacket is from the DownTek collection.\\nTRUE ANSWER: The DownTek collection\\nGRADE:\", 'role': 'user'}], 'model': 'llama3:8b', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-10 16:08:18 - DEBUG - _base_client.py:_request:949 - Sending HTTP Request: POST http://localhost:11434/v1/chat/completions\n",
      "2024-06-10 16:08:18 - DEBUG - _trace.py:trace:45 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:18 - DEBUG - _trace.py:trace:45 - send_request_headers.complete\n",
      "2024-06-10 16:08:18 - DEBUG - _trace.py:trace:45 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:18 - DEBUG - _trace.py:trace:45 - send_request_body.complete\n",
      "2024-06-10 16:08:18 - DEBUG - _trace.py:trace:45 - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:26 - DEBUG - _trace.py:trace:45 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Mon, 10 Jun 2024 14:08:26 GMT'), (b'Content-Length', b'515')])\n",
      "2024-06-10 16:08:26 - INFO - _client.py:_send_single_request:1026 - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-10 16:08:26 - DEBUG - _trace.py:trace:45 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:26 - DEBUG - _trace.py:trace:45 - receive_response_body.complete\n",
      "2024-06-10 16:08:26 - DEBUG - _trace.py:trace:45 - response_closed.started\n",
      "2024-06-10 16:08:26 - DEBUG - _trace.py:trace:45 - response_closed.complete\n",
      "2024-06-10 16:08:26 - DEBUG - _base_client.py:_request:988 - HTTP Response: POST http://localhost:11434/v1/chat/completions \"200 OK\" Headers({'content-type': 'application/json', 'date': 'Mon, 10 Jun 2024 14:08:26 GMT', 'content-length': '515'})\n",
      "2024-06-10 16:08:26 - DEBUG - _base_client.py:_request:996 - request_id: None\n",
      "2024-06-10 16:08:26 - DEBUG - _base_client.py:_build_request:446 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': \"You are a teacher grading a quiz.\\nYou are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\\n\\nExample Format:\\nQUESTION: question here\\nSTUDENT ANSWER: student's answer here\\nTRUE ANSWER: true answer here\\nGRADE: CORRECT or INCORRECT here\\n\\nGrade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \\n\\nQUESTION: What is the weight of a pair of Women's Campside Oxfords?\\nSTUDENT ANSWER: According to the description, the approximate weight of a pair of Women's Campside Oxfords is 1 lb. 1 oz. per pair.\\nTRUE ANSWER: 1 lb.1 oz. per pair.\\nGRADE:\", 'role': 'user'}], 'model': 'llama3:8b', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-10 16:08:26 - DEBUG - _base_client.py:_request:949 - Sending HTTP Request: POST http://localhost:11434/v1/chat/completions\n",
      "2024-06-10 16:08:26 - DEBUG - _trace.py:trace:45 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:26 - DEBUG - _trace.py:trace:45 - send_request_headers.complete\n",
      "2024-06-10 16:08:26 - DEBUG - _trace.py:trace:45 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:26 - DEBUG - _trace.py:trace:45 - send_request_body.complete\n",
      "2024-06-10 16:08:26 - DEBUG - _trace.py:trace:45 - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:36 - DEBUG - _trace.py:trace:45 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Mon, 10 Jun 2024 14:08:36 GMT'), (b'Content-Length', b'535')])\n",
      "2024-06-10 16:08:36 - INFO - _client.py:_send_single_request:1026 - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-10 16:08:36 - DEBUG - _trace.py:trace:45 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:36 - DEBUG - _trace.py:trace:45 - receive_response_body.complete\n",
      "2024-06-10 16:08:36 - DEBUG - _trace.py:trace:45 - response_closed.started\n",
      "2024-06-10 16:08:36 - DEBUG - _trace.py:trace:45 - response_closed.complete\n",
      "2024-06-10 16:08:36 - DEBUG - _base_client.py:_request:988 - HTTP Response: POST http://localhost:11434/v1/chat/completions \"200 OK\" Headers({'content-type': 'application/json', 'date': 'Mon, 10 Jun 2024 14:08:36 GMT', 'content-length': '535'})\n",
      "2024-06-10 16:08:36 - DEBUG - _base_client.py:_request:996 - request_id: None\n",
      "2024-06-10 16:08:36 - DEBUG - _base_client.py:_build_request:446 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'You are a teacher grading a quiz.\\nYou are given a question, the student\\'s answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\\n\\nExample Format:\\nQUESTION: question here\\nSTUDENT ANSWER: student\\'s answer here\\nTRUE ANSWER: true answer here\\nGRADE: CORRECT or INCORRECT here\\n\\nGrade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \\n\\nQUESTION: What is the purpose of the recycled waterhog dog mat?\\nSTUDENT ANSWER: According to the description, the purpose of the Recycled Waterhog Dog Mat is to \"Protect your floors from spills and splashing\" by keeping dirt and water off your floors and plastic out of landfills, trails, and oceans. It\\'s designed to be an ultradurable mat made from recycled plastic materials that can withstand the messes and mishaps of dogs.\\nTRUE ANSWER: The purpose of the recycled waterhog dog mat is to protect floors from spills and splashing with its ultradurable construction made from recycled plastic materials.\\nGRADE:', 'role': 'user'}], 'model': 'llama3:8b', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-10 16:08:36 - DEBUG - _base_client.py:_request:949 - Sending HTTP Request: POST http://localhost:11434/v1/chat/completions\n",
      "2024-06-10 16:08:36 - DEBUG - _trace.py:trace:45 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:36 - DEBUG - _trace.py:trace:45 - send_request_headers.complete\n",
      "2024-06-10 16:08:36 - DEBUG - _trace.py:trace:45 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:36 - DEBUG - _trace.py:trace:45 - send_request_body.complete\n",
      "2024-06-10 16:08:36 - DEBUG - _trace.py:trace:45 - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:54 - DEBUG - _trace.py:trace:45 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Mon, 10 Jun 2024 14:08:54 GMT'), (b'Content-Length', b'913')])\n",
      "2024-06-10 16:08:54 - INFO - _client.py:_send_single_request:1026 - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-10 16:08:54 - DEBUG - _trace.py:trace:45 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:54 - DEBUG - _trace.py:trace:45 - receive_response_body.complete\n",
      "2024-06-10 16:08:54 - DEBUG - _trace.py:trace:45 - response_closed.started\n",
      "2024-06-10 16:08:54 - DEBUG - _trace.py:trace:45 - response_closed.complete\n",
      "2024-06-10 16:08:54 - DEBUG - _base_client.py:_request:988 - HTTP Response: POST http://localhost:11434/v1/chat/completions \"200 OK\" Headers({'content-type': 'application/json', 'date': 'Mon, 10 Jun 2024 14:08:54 GMT', 'content-length': '913'})\n",
      "2024-06-10 16:08:54 - DEBUG - _base_client.py:_request:996 - request_id: None\n",
      "2024-06-10 16:08:54 - DEBUG - _base_client.py:_build_request:446 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': \"You are a teacher grading a quiz.\\nYou are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\\n\\nExample Format:\\nQUESTION: question here\\nSTUDENT ANSWER: student's answer here\\nTRUE ANSWER: true answer here\\nGRADE: CORRECT or INCORRECT here\\n\\nGrade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \\n\\nQUESTION: What is the main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit?\\nSTUDENT ANSWER: According to the description, one of the main features of the Infant and Toddler Girls' Coastal Chill Swimsuit is its UPF 50+ rated fabric, which provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays.\\nTRUE ANSWER: The main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit is its bright colors, ruffles, and exclusive whimsical prints.\\nGRADE:\", 'role': 'user'}], 'model': 'llama3:8b', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2024-06-10 16:08:54 - DEBUG - _base_client.py:_request:949 - Sending HTTP Request: POST http://localhost:11434/v1/chat/completions\n",
      "2024-06-10 16:08:54 - DEBUG - _trace.py:trace:45 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:54 - DEBUG - _trace.py:trace:45 - send_request_headers.complete\n",
      "2024-06-10 16:08:54 - DEBUG - _trace.py:trace:45 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-10 16:08:54 - DEBUG - _trace.py:trace:45 - send_request_body.complete\n",
      "2024-06-10 16:08:54 - DEBUG - _trace.py:trace:45 - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-10 16:09:11 - DEBUG - _trace.py:trace:45 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Mon, 10 Jun 2024 14:09:11 GMT'), (b'Content-Length', b'801')])\n",
      "2024-06-10 16:09:11 - INFO - _client.py:_send_single_request:1026 - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-10 16:09:11 - DEBUG - _trace.py:trace:45 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-10 16:09:11 - DEBUG - _trace.py:trace:45 - receive_response_body.complete\n",
      "2024-06-10 16:09:11 - DEBUG - _trace.py:trace:45 - response_closed.started\n",
      "2024-06-10 16:09:11 - DEBUG - _trace.py:trace:45 - response_closed.complete\n",
      "2024-06-10 16:09:11 - DEBUG - _base_client.py:_request:988 - HTTP Response: POST http://localhost:11434/v1/chat/completions \"200 OK\" Headers({'content-type': 'application/json', 'date': 'Mon, 10 Jun 2024 14:09:11 GMT', 'content-length': '801'})\n",
      "2024-06-10 16:09:11 - DEBUG - _base_client.py:_request:996 - request_id: None\n"
     ]
    }
   ],
   "source": [
    "graded_outputs = eval_chain.evaluate(examples, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "71abba6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"What is the main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit?\",\n",
       " 'answer': \"The main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit is its bright colors, ruffles, and exclusive whimsical prints.\",\n",
       " 'result': \"According to the description, one of the main features of the Infant and Toddler Girls' Coastal Chill Swimsuit is its UPF 50+ rated fabric, which provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays.\"}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "20ce03fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'results': 'GRADE: CORRECT'},\n",
       " {'results': 'QUESTION: What collection is the Ultra-Lofty 850 Stretch Down Hooded Jacket from?\\nSTUDENT ANSWER: The Ultra-Lofty 850 Stretch Down Hooded Jacket is from the DownTek collection.\\nTRUE ANSWER: The DownTek collection\\nGRADE: CORRECT'},\n",
       " {'results': \"QUESTION: What is the weight of a pair of Women's Campside Oxfords?\\nSTUDENT ANSWER: According to the description, the approximate weight of a pair of Women's Campside Oxfords is 1 lb. 1 oz. per pair.\\nTRUE ANSWER: 1 lb.1 oz. per pair.\\nGRADE: CORRECT\"},\n",
       " {'results': 'QUESTION: What is the purpose of the recycled waterhog dog mat?\\nSTUDENT ANSWER: According to the description, the purpose of the Recycled Waterhog Dog Mat is to \"Protect your floors from spills and splashing\" by keeping dirt and water off your floors and plastic out of landfills, trails, and oceans. It\\'s designed to be an ultradurable mat made from recycled plastic materials that can withstand the messes and mishaps of dogs.\\nTRUE ANSWER: The purpose of the recycled waterhog dog mat is to protect floors from spills and splashing with its ultradurable construction made from recycled plastic materials.\\nGRADE: CORRECT'},\n",
       " {'results': \"QUESTION: What is the main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit?\\nSTUDENT ANSWER: According to the description, one of the main features of the Infant and Toddler Girls' Coastal Chill Swimsuit is its UPF 50+ rated fabric, which provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays.\\nTRUE ANSWER: The main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit is its bright colors, ruffles, and exclusive whimsical prints.\\nGRADE: INCORRECT\"}]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Graded outputs from Ollama\n",
    "graded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "feb9e266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'results': 'CORRECT'},\n",
       " {'results': 'CORRECT'},\n",
       " {'results': 'CORRECT'},\n",
       " {'results': 'CORRECT'},\n",
       " {'results': 'INCORRECT'}]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Graded outputs from OpenAI\n",
    "graded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "3437cfbe",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Question: Do the Cozy Comfort Pullover Set have side pockets?\n",
      "Real Answer: Yes\n",
      "Predicted Answer: According to the product description, yes, the Cozy Comfort Pullover Set has side pockets in the pull-on pants.\n",
      "Predicted Grade: GRADE: CORRECT\n",
      "\n",
      "Example 1:\n",
      "Question: What collection is the Ultra-Lofty 850 Stretch Down Hooded Jacket from?\n",
      "Real Answer: The DownTek collection\n",
      "Predicted Answer: The Ultra-Lofty 850 Stretch Down Hooded Jacket is from the DownTek collection.\n",
      "Predicted Grade: QUESTION: What collection is the Ultra-Lofty 850 Stretch Down Hooded Jacket from?\n",
      "STUDENT ANSWER: The Ultra-Lofty 850 Stretch Down Hooded Jacket is from the DownTek collection.\n",
      "TRUE ANSWER: The DownTek collection\n",
      "GRADE: CORRECT\n",
      "\n",
      "Example 2:\n",
      "Question: What is the weight of a pair of Women's Campside Oxfords?\n",
      "Real Answer: 1 lb.1 oz. per pair.\n",
      "Predicted Answer: According to the description, the approximate weight of a pair of Women's Campside Oxfords is 1 lb. 1 oz. per pair.\n",
      "Predicted Grade: QUESTION: What is the weight of a pair of Women's Campside Oxfords?\n",
      "STUDENT ANSWER: According to the description, the approximate weight of a pair of Women's Campside Oxfords is 1 lb. 1 oz. per pair.\n",
      "TRUE ANSWER: 1 lb.1 oz. per pair.\n",
      "GRADE: CORRECT\n",
      "\n",
      "Example 3:\n",
      "Question: What is the purpose of the recycled waterhog dog mat?\n",
      "Real Answer: The purpose of the recycled waterhog dog mat is to protect floors from spills and splashing with its ultradurable construction made from recycled plastic materials.\n",
      "Predicted Answer: According to the description, the purpose of the Recycled Waterhog Dog Mat is to \"Protect your floors from spills and splashing\" by keeping dirt and water off your floors and plastic out of landfills, trails, and oceans. It's designed to be an ultradurable mat made from recycled plastic materials that can withstand the messes and mishaps of dogs.\n",
      "Predicted Grade: QUESTION: What is the purpose of the recycled waterhog dog mat?\n",
      "STUDENT ANSWER: According to the description, the purpose of the Recycled Waterhog Dog Mat is to \"Protect your floors from spills and splashing\" by keeping dirt and water off your floors and plastic out of landfills, trails, and oceans. It's designed to be an ultradurable mat made from recycled plastic materials that can withstand the messes and mishaps of dogs.\n",
      "TRUE ANSWER: The purpose of the recycled waterhog dog mat is to protect floors from spills and splashing with its ultradurable construction made from recycled plastic materials.\n",
      "GRADE: CORRECT\n",
      "\n",
      "Example 4:\n",
      "Question: What is the main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit?\n",
      "Real Answer: The main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit is its bright colors, ruffles, and exclusive whimsical prints.\n",
      "Predicted Answer: According to the description, one of the main features of the Infant and Toddler Girls' Coastal Chill Swimsuit is its UPF 50+ rated fabric, which provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays.\n",
      "Predicted Grade: QUESTION: What is the main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit?\n",
      "STUDENT ANSWER: According to the description, one of the main features of the Infant and Toddler Girls' Coastal Chill Swimsuit is its UPF 50+ rated fabric, which provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays.\n",
      "TRUE ANSWER: The main feature of the Infant and Toddler Girls' Coastal Chill Swimsuit is its bright colors, ruffles, and exclusive whimsical prints.\n",
      "GRADE: INCORRECT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    print(\"Predicted Grade: \" + graded_outputs[i]['results'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce542854",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
